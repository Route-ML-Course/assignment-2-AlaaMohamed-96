# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xmm2b-GSg6kidb5co51rq0-PC4HWWQAj
"""

import requests
from bs4 import BeautifulSoup
import csv
from itertools import zip_longest

team1 = []
team2 = []
res = []
Static = []

count = ['519','518','517','516','515','533','532','531','530','529','548','676','675','674','700','699','817','840','839','841']
for i in count :
  result = requests.get("https://www.yallakora.com/epl/2761/fixtures/%d8%a7%d9%84%d8%af%d9%88%d8%b1%d9%8a-%d8%a7%d9%84%d8%a5%d9%86%d8%ac%d9%84%d9%8a%d8%b2%d9%8a?roundid=10"+i)
  src = result.content
  soup = BeautifulSoup(src,'lxml')
  match =soup.find_all('li',{"class":"finish"})
  # print(match)

  for Match in match :
    team1.append(Match.find_next('div',{"class":"teams teamA"}).text)
    team2.append(Match.find_next('div',{"class":"teams teamB"}).text)
    res.append(Match.find_next('div',{"class":"MResult"}).text)
    corner = Match.find_next('div',{"class":"leftCol"}).find_next('a')["href"]
    corner_link = "https://www.yallakora.com"+corner
    corner_res = requests.get(corner_link)
    corner_src = corner_res.content
    corner_soup = BeautifulSoup(corner_src,'lxml')
    Corner = corner_soup.find_all('section',{"class":"matchDetailsTabs"})
    print(Corner)
    for con in Corner :
      # static = con.find_next('li').text
      Static.append(con.find_next('div',{"class":"statsDiv"}))

  exp = zip_longest(*[team1,team2,res,Static])
  with open('data.csv','w') as f :
    f = csv.writer(f)
    f.writerow(["team 1","team 2","the score","statices"])
    f.writerows(exp)